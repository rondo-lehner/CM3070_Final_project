{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed53b72f-60e2-4e4b-ab3b-67aeb2c7434c",
   "metadata": {},
   "source": [
    "# Trained model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d1cdf-07f2-483e-8d4b-9c97d9637f97",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aad327-049c-4b31-bbc3-2a2e0e3c13af",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979ba4e3-99fe-46ff-8905-d6057c0eeb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb47265-a57b-4d87-a2ca-b7ce48a8f70f",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e71dd5cb-6081-45c8-8924-c493a3d28858",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_DIR = os.path.join(os.getcwd(), '..', 'models', 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a804d40-f80d-4679-8794-961c808267ec",
   "metadata": {},
   "source": [
    "### Helpers and utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dcc3d42-f24a-46de-829b-d465aae06255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricTracker:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.mIoU = tf.keras.metrics.OneHotMeanIoU(\n",
    "            num_classes = 7,\n",
    "            name = f'mIoU_{model_name}'\n",
    "        )\n",
    "        self.class_names = ['urban_land', 'agriculture_land', 'rangeland', 'forest_land', 'water', 'barren_land', 'unknown']\n",
    "        self.IoU_scores = [tf.keras.metrics.OneHotIoU(\n",
    "            num_classes = 7,\n",
    "            name = f'IoU_{model_name}_{self.class_names[i]}',\n",
    "            target_class_ids = [i]\n",
    "        ) for i in range(7)]\n",
    "        \n",
    "    def update_state(self, mask, mask_pred):\n",
    "        self.mIoU.update_state(mask, mask_pred)\n",
    "        for metric in self.IoU_scores:\n",
    "            metric.update_state(mask, mask_pred)\n",
    "\n",
    "    def result(self):\n",
    "        table = [['all (mIoU)', self.mIoU.result().numpy()]]\n",
    "        for i,m in enumerate(self.IoU_scores):\n",
    "            table.append([self.class_names[i], m.result().numpy()])\n",
    "                          \n",
    "        print(tabulate(table, headers=['class', 'score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe4ab9c-50ee-46fb-b934-c8d15f864ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_rgb(indexed_image):\n",
    "    palette = [\n",
    "        [0, 255, 255],   # urban_land\n",
    "        [255, 255, 0],   # agriculture_land\n",
    "        [255, 0, 255],   # rangeland\n",
    "        [0, 255, 0],     # forest_land\n",
    "        [0, 0, 255],     # water\n",
    "        [255, 255, 255], # barren_land\n",
    "        [0, 0, 0]        # unknown\n",
    "    ]\n",
    "\n",
    "    # Convert indexed image to one-hot representation\n",
    "    one_hot_map = tf.one_hot(tf.squeeze(indexed_image, axis=-1), depth=len(palette), dtype=tf.float32)\n",
    "\n",
    "    # Use one-hot map and palette to reconstruct RGB image\n",
    "    reconstructed_image = tf.reduce_sum(tf.expand_dims(one_hot_map, axis=-1) * tf.constant(palette, dtype=tf.float32), axis=-2)\n",
    "\n",
    "    return tf.cast(reconstructed_image, dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ddb5a0e-ed5b-48a5-91bd-6700fae42608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list, file_name):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    print(len(display_list))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        data = display_list[i][0]\n",
    "        # if i > 0:\n",
    "        #     data = index_to_rgb(data)\n",
    "        plt.imshow(tf.keras.utils.array_to_img(data, data_format='channels_last'))\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(file_name[0].numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc58eb7-9fea-4d3e-ac73-df65a8bd4633",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec7a0a-a802-4b82-b255-e0d7dda56556",
   "metadata": {},
   "source": [
    "### Early convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e063b9f9-2645-41f7-b15b-4c5d1ffe08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.pipelines import convnet_pipeline\n",
    "from src.models import early_convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4220da-b459-402d-be89-077f24427ae4",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cff413-91e3-4b75-a68b-1dcf6997213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_IMAGES = 1\n",
    "BATCH_SIZE_PATCHES = 1\n",
    "IMAGE_SIZE = 224\n",
    "PATCH_SIZE = 40\n",
    "PATCH_SIZE_ANNOTATION = 2\n",
    "PATCH_STRIDE = 1\n",
    "SLICE_TRAIN = ':1'\n",
    "SLICE_VALID = ':1'\n",
    "SLICE_TEST = '85%:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09d1d61-1a17-4636-8892-1a18e6c14433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 20:07:24.067536: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "input_pipeline = convnet_pipeline.ConvnetPipeline(\n",
    "    SLICE_TRAIN,\n",
    "    SLICE_VALID,\n",
    "    SLICE_TEST,\n",
    "    BATCH_SIZE_IMAGES,\n",
    "    BATCH_SIZE_PATCHES,\n",
    "    IMAGE_SIZE,\n",
    "    PATCH_SIZE,\n",
    "    PATCH_SIZE_ANNOTATION,\n",
    "    PATCH_STRIDE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0f511-79fc-4716-8a50-6075660d476e",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f348d2c-e749-4732-95e6-1d48d49dcfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd4d44d27a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = early_convnet.EarlyConvnet()\n",
    "model.build((None, PATCH_SIZE + 20, PATCH_SIZE + 20, 3))     # 20 is for mirror padding border\n",
    "checkpoint_filepath = os.path.join(os.getcwd(),'..', 'models', 'ckpt', 'early_convnet')\n",
    "latest = tf.train.latest_checkpoint(checkpoint_filepath)\n",
    "\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf07a5-c04d-4b83-bfff-fb3dcd25805f",
   "metadata": {},
   "source": [
    "### Metrics and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a3e37a-2cd3-44b6-82c6-6b326433fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = MetricTracker('convnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d84c5a7b-9d74-48e3-9b2e-b1adcd0fae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patches, _, img, mask, file_name in input_pipeline.test:\n",
    "    pred = model.predict(patches, verbose=0)\n",
    "    mask_pred = tf.reshape(pred, shape=(1, 225, 225, 7))\n",
    "    # \"lose\" the extra pixel: 225 => 224\n",
    "    mask_pred = tf.image.crop_to_bounding_box(\n",
    "            image=mask_pred,\n",
    "            offset_height=0,\n",
    "            offset_width=0,\n",
    "            target_height=224,\n",
    "            target_width=224\n",
    "        )\n",
    "    tracker.update_state(mask, mask_pred)\n",
    "    # mask_indexed = tf.reshape(tf.argmax(input=mask, axis=3), shape=(1, 224, 224, 1))\n",
    "    pred_indexed = tf.reshape(tf.argmax(input=mask_pred, axis=3), shape=(1, 224, 224, 1))\n",
    "    # mask_rgb = index_to_rgb(mask_indexed)\n",
    "    pred_rgb = index_to_rgb(pred_indexed)\n",
    "\n",
    "    file_path = os.path.join(PREDICTIONS_DIR, tracker.model_name, tf.compat.as_str(file_name[0].numpy()))\n",
    "    tf.keras.utils.save_img(file_path, pred_rgb[0], data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e776a-004e-4385-b2f2-10754daaba2b",
   "metadata": {},
   "source": [
    "### FCN-8s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adecbf8-e1e0-45a6-8ef4-7db84aa599e4",
   "metadata": {},
   "source": [
    "### U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9409d1-6756-4c15-8848-5af59eb071fd",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
