{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed53b72f-60e2-4e4b-ab3b-67aeb2c7434c",
   "metadata": {},
   "source": [
    "# Trained model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d1cdf-07f2-483e-8d4b-9c97d9637f97",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aad327-049c-4b31-bbc3-2a2e0e3c13af",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979ba4e3-99fe-46ff-8905-d6057c0eeb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 20:39:44.138098: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb47265-a57b-4d87-a2ca-b7ce48a8f70f",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71dd5cb-6081-45c8-8924-c493a3d28858",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_DIR = os.path.join(os.getcwd(), '..', 'models', 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a804d40-f80d-4679-8794-961c808267ec",
   "metadata": {},
   "source": [
    "### Helpers and utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcc3d42-f24a-46de-829b-d465aae06255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricTracker:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.mIoU = tf.keras.metrics.OneHotMeanIoU(\n",
    "            num_classes = 7,\n",
    "            name = f'mIoU_{model_name}'\n",
    "        )\n",
    "        self.class_names = ['urban_land', 'agriculture_land', 'rangeland', 'forest_land', 'water', 'barren_land', 'unknown']\n",
    "        self.IoU_scores = [tf.keras.metrics.OneHotIoU(\n",
    "            num_classes = 7,\n",
    "            name = f'IoU_{model_name}_{self.class_names[i]}',\n",
    "            target_class_ids = [i]\n",
    "        ) for i in range(7)]\n",
    "        \n",
    "    def update_state(self, mask, mask_pred):\n",
    "        self.mIoU.update_state(mask, mask_pred)\n",
    "        for metric in self.IoU_scores:\n",
    "            metric.update_state(mask, mask_pred)\n",
    "\n",
    "    def result(self):\n",
    "        table = [['all (mIoU)', self.mIoU.result().numpy()]]\n",
    "        for i,m in enumerate(self.IoU_scores):\n",
    "            table.append([self.class_names[i], m.result().numpy()])\n",
    "                          \n",
    "        print(tabulate(table, headers=['class', 'score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe4ab9c-50ee-46fb-b934-c8d15f864ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_rgb(indexed_image):\n",
    "    palette = [\n",
    "        [0, 255, 255],   # urban_land\n",
    "        [255, 255, 0],   # agriculture_land\n",
    "        [255, 0, 255],   # rangeland\n",
    "        [0, 255, 0],     # forest_land\n",
    "        [0, 0, 255],     # water\n",
    "        [255, 255, 255], # barren_land\n",
    "        [0, 0, 0]        # unknown\n",
    "    ]\n",
    "\n",
    "    # Convert indexed image to one-hot representation\n",
    "    one_hot_map = tf.one_hot(tf.squeeze(indexed_image, axis=-1), depth=len(palette), dtype=tf.float32)\n",
    "\n",
    "    # Use one-hot map and palette to reconstruct RGB image\n",
    "    reconstructed_image = tf.reduce_sum(tf.expand_dims(one_hot_map, axis=-1) * tf.constant(palette, dtype=tf.float32), axis=-2)\n",
    "\n",
    "    return tf.cast(reconstructed_image, dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddb5a0e-ed5b-48a5-91bd-6700fae42608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list, file_name):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    print(len(display_list))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        data = display_list[i][0]\n",
    "        # if i > 0:\n",
    "        #     data = index_to_rgb(data)\n",
    "        plt.imshow(tf.keras.utils.array_to_img(data, data_format='channels_last'))\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(file_name[0].numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc58eb7-9fea-4d3e-ac73-df65a8bd4633",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec7a0a-a802-4b82-b255-e0d7dda56556",
   "metadata": {},
   "source": [
    "### Early convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e063b9f9-2645-41f7-b15b-4c5d1ffe08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.pipelines import convnet_pipeline\n",
    "from src.models import early_convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4220da-b459-402d-be89-077f24427ae4",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cff413-91e3-4b75-a68b-1dcf6997213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_IMAGES = 1\n",
    "BATCH_SIZE_PATCHES = 1\n",
    "IMAGE_SIZE = 224\n",
    "PATCH_SIZE = 40\n",
    "PATCH_SIZE_ANNOTATION = 2\n",
    "PATCH_STRIDE = 1\n",
    "SLICE_TRAIN = ':1'\n",
    "SLICE_VALID = ':1'\n",
    "SLICE_TEST = '85%:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09d1d61-1a17-4636-8892-1a18e6c14433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 20:07:24.067536: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "input_pipeline = convnet_pipeline.ConvnetPipeline(\n",
    "    SLICE_TRAIN,\n",
    "    SLICE_VALID,\n",
    "    SLICE_TEST,\n",
    "    BATCH_SIZE_IMAGES,\n",
    "    BATCH_SIZE_PATCHES,\n",
    "    IMAGE_SIZE,\n",
    "    PATCH_SIZE,\n",
    "    PATCH_SIZE_ANNOTATION,\n",
    "    PATCH_STRIDE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0f511-79fc-4716-8a50-6075660d476e",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f348d2c-e749-4732-95e6-1d48d49dcfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd4d44d27a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = early_convnet.EarlyConvnet()\n",
    "model.build((None, PATCH_SIZE + 20, PATCH_SIZE + 20, 3))     # 20 is for mirror padding border\n",
    "checkpoint_filepath = os.path.join(os.getcwd(),'..', 'models', 'ckpt', 'early_convnet')\n",
    "latest = tf.train.latest_checkpoint(checkpoint_filepath)\n",
    "\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf07a5-c04d-4b83-bfff-fb3dcd25805f",
   "metadata": {},
   "source": [
    "#### Metrics and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a3e37a-2cd3-44b6-82c6-6b326433fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_1 = MetricTracker('convnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d84c5a7b-9d74-48e3-9b2e-b1adcd0fae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patches, _, img, mask, file_name in input_pipeline.test:\n",
    "    pred = model.predict(patches, verbose=0)\n",
    "    mask_pred = tf.reshape(pred, shape=(1, 225, 225, 7))\n",
    "    # \"lose\" the extra pixel: 225 => 224\n",
    "    mask_pred = tf.image.crop_to_bounding_box(\n",
    "            image=mask_pred,\n",
    "            offset_height=0,\n",
    "            offset_width=0,\n",
    "            target_height=224,\n",
    "            target_width=224\n",
    "        )\n",
    "    tracker_1.update_state(mask, mask_pred)\n",
    "    # mask_indexed = tf.reshape(tf.argmax(input=mask, axis=3), shape=(1, 224, 224, 1))\n",
    "    pred_indexed = tf.reshape(tf.argmax(input=mask_pred, axis=3), shape=(1, 224, 224, 1))\n",
    "    # mask_rgb = index_to_rgb(mask_indexed)\n",
    "    pred_rgb = index_to_rgb(pred_indexed)\n",
    "\n",
    "    file_path = os.path.join(PREDICTIONS_DIR, tracker.model_name, tf.compat.as_str(file_name[0].numpy()))\n",
    "    tf.keras.utils.save_img(file_path, pred_rgb[0], data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e776a-004e-4385-b2f2-10754daaba2b",
   "metadata": {},
   "source": [
    "### FCN-8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9dcf32-726a-4d22-ad02-6bb35d00ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import src.data.pipelines.fcn_pipeline as fcn_pipeline\n",
    "from src.models import fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0a1d6-2ef0-4cc8-92ab-c9c4ca160f86",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdc0a86-cb36-4152-a432-11a143ac0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_TRAIN = \":1\"\n",
    "SPLIT_VALID = \":1\"\n",
    "SPLIT_TEST = \"85%:\"\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50a5c3b-8ef2-4577-a3d3-5f7d8a1fcc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 20:26:34.765983: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "(_, _, test) = fcn_pipeline.getFCNPipeline(\n",
    "        SPLIT_TRAIN,\n",
    "        SPLIT_VALID,\n",
    "        SPLIT_TEST,\n",
    "        BATCH_SIZE,\n",
    "        IMAGE_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a994f-25dd-4482-9849-e145475affaa",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8fcbf3-7d61-44fb-824a-28a8f25242da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn.get_fcn_8s()\n",
    "# checkpoint_filepath = os.path.join(os.getcwd(),'..', 'models', 'ckpt', 'fcn')\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_filepath)\n",
    "\n",
    "# model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a3287-08f7-49d5-bb95-535e26cce13a",
   "metadata": {},
   "source": [
    "#### Metrics and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb278a9b-7fbb-474b-bd34-068977b74cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_2 = MetricTracker('fcn-8s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d956c9-76e2-43e3-981d-bf92e1b2d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask, file_name in test.take(2):\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    \n",
    "    tracker_2.update_state(mask, pred)\n",
    "    pred_indexed = tf.reshape(tf.argmax(input=pred, axis=3), shape=(1, 224, 224, 1))\n",
    "    pred_rgb = index_to_rgb(pred_indexed)\n",
    "\n",
    "    file_path = os.path.join(PREDICTIONS_DIR, tracker_2.model_name, tf.compat.as_str(file_name[0].numpy()))\n",
    "    tf.keras.utils.save_img(file_path, pred_rgb[0], data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adecbf8-e1e0-45a6-8ef4-7db84aa599e4",
   "metadata": {},
   "source": [
    "### U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fd22b3-5233-4307-8edc-953f31ceea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import src.data.pipelines.unet_pipeline as unet_pipeline\n",
    "from src.models import unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f3e52-e804-432a-a8df-c705d6a80a38",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ba7bf6-6c55-46a9-ab26-4a8a93fee6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_TRAIN = \":1\"\n",
    "SPLIT_VALID = \":1\"\n",
    "SPLIT_TEST = \"85%:\"\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 228    # value model-compatible value to 224\n",
    "BORDER = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fd93ba-7249-44dc-9d09-0464fd8733a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 20:39:50.065923: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "(_, _, test) = unet_pipeline.getUNetPipeline(\n",
    "        SPLIT_TRAIN,\n",
    "        SPLIT_VALID,\n",
    "        SPLIT_TEST,\n",
    "        BATCH_SIZE,\n",
    "        IMAGE_SIZE,\n",
    "        BORDER\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d3428-5fa2-4f8c-a14a-d34e19470e47",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80bc9a35-9efa-47b4-b9f6-68a9c18293ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = IMAGE_SIZE + BORDER * 2\n",
    "model = unet.get_UNet(input_shape=(size, size, 3))\n",
    "# checkpoint_filepath = os.path.join(os.getcwd(),'..', 'models', 'ckpt', 'fcn')\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_filepath)\n",
    "\n",
    "# model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4728433-c66e-4a23-87aa-43f5d964eb5b",
   "metadata": {},
   "source": [
    "#### Metrics and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c6e9fa-c0d3-4a27-90dd-0b1d1987e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_3 = MetricTracker('unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab61185-33e5-46ee-b460-8415fa6011b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask, file_name in test.take(2):\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    \n",
    "    tracker_3.update_state(mask, pred)\n",
    "    pred_indexed = tf.reshape(tf.argmax(input=pred, axis=3), shape=(1, 228, 228, 1))\n",
    "    pred_rgb = index_to_rgb(pred_indexed)\n",
    "    pred_rgb = tf.image.resize(pred_rgb, (224, 224), method='nearest')\n",
    "\n",
    "    file_path = os.path.join(PREDICTIONS_DIR, tracker_3.model_name, tf.compat.as_str(file_name[0].numpy()))\n",
    "    tf.keras.utils.save_img(file_path, pred_rgb[0], data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9409d1-6756-4c15-8848-5af59eb071fd",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
