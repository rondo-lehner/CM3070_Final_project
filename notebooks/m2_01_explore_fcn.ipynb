{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244e6422-7169-45af-92ee-b448870a18ec",
   "metadata": {},
   "source": [
    "# Explore implementation of FCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ddda50-fcf1-466c-9c46-4b6cf1ef2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import src.data.datasets.deep_globe_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c746a18-71c4-4572-bef5-91f4b9145bd1",
   "metadata": {},
   "source": [
    "## Reuse code from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d2b6ae-0b54-481e-a4f1-57574ba875c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 612\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f700f1f-d530-4fe5-b5a2-1bc0b48a3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b4568b-13b3-4277-8951-9ae682a26519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_index(image):\n",
    "    palette = [\n",
    "        [0, 255, 255],   # urban_land\n",
    "        [255, 255, 0],   # agriculture_land\n",
    "        [255, 0, 255],   # rangeland\n",
    "        [0, 255, 0],     # forest_land\n",
    "        [0, 0, 255],     # water\n",
    "        [255, 255, 255], # barren_land\n",
    "        [0, 0, 0]        # unknown\n",
    "    ]\n",
    "    \n",
    "    one_hot_map = []\n",
    "    for colour in palette:\n",
    "        class_map = tf.reduce_all(tf.equal(image, colour), axis=-1)\n",
    "        one_hot_map.append(class_map)\n",
    "    one_hot_map = tf.stack(one_hot_map, axis=-1)\n",
    "    one_hot_map = tf.cast(one_hot_map, tf.uint8)\n",
    "    indexed = tf.math.argmax(one_hot_map, axis=2)\n",
    "    indexed = tf.cast(indexed, dtype=tf.uint8)\n",
    "    indexed = tf.expand_dims(indexed, -1)\n",
    "\n",
    "    return indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b16d726b-155c-4be0-9e8e-5a9881853264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(datapoint, image_size):\n",
    "    \n",
    "    images = tf.image.resize(datapoint['image'], (image_size, image_size))\n",
    "\n",
    "    annotations = tf.map_fn(rgb_to_index, datapoint['segmentation_mask'])\n",
    "    annotations = tf.image.resize(annotations, (image_size, image_size), method='nearest')\n",
    "    \n",
    "    images = normalize(images)\n",
    "\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2416358-dfeb-4a8b-a8c0-bed9ea09de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    print(len(display_list))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e06716-38cb-406d-b3de-762095618338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_valid, ds_test), ds_info = tfds.load(\n",
    "    name='deep_globe_2018',\n",
    "    download=False,\n",
    "    with_info=True,\n",
    "    split=['all_images[700:710]', 'all_images[7:9]', 'all_images[9:10]']\n",
    ")\n",
    "train_batches = (\n",
    "    ds_train\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x: load_images(x, IMAGE_SIZE), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "validation_batches = (\n",
    "    ds_valid\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x: load_images(x, IMAGE_SIZE), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_batches = (\n",
    "    ds_test\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x: load_images(x, IMAGE_SIZE), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926ea0e-ee1b-44c8-9cbf-605b592aa880",
   "metadata": {},
   "source": [
    "## Explore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23cfbad0-2136-476a-b9c8-a0017937adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62b7b9cb-99bd-4436-9a6b-4fa229c50de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in train_batches.take(1):\n",
    "    y = base_model(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "238b60b5-0806-4bcf-95e6-638e1ada88ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 612, 612, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 612, 612, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 612, 612, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 306, 306, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 306, 306, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 306, 306, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 153, 153, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 153, 153, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 153, 153, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 153, 153, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 76, 76, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 76, 76, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 76, 76, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 76, 76, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 38, 38, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 38, 38, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 38, 38, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 38, 38, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 19, 19, 512)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67abb33a-e28b-45b6-8ada-c82483c9fbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 19, 19, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = base_model(inputs)\n",
    "x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b8715-9734-4cec-a069-565e2c30aebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
