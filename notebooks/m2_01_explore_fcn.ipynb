{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244e6422-7169-45af-92ee-b448870a18ec",
   "metadata": {},
   "source": [
    "# Explore implementation of FCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ddda50-fcf1-466c-9c46-4b6cf1ef2e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 20:13:22.398213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import src.data.datasets.deep_globe_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c746a18-71c4-4572-bef5-91f4b9145bd1",
   "metadata": {},
   "source": [
    "## Reuse code from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d2b6ae-0b54-481e-a4f1-57574ba875c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f700f1f-d530-4fe5-b5a2-1bc0b48a3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b4568b-13b3-4277-8951-9ae682a26519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_index(image):\n",
    "    palette = [\n",
    "        [0, 255, 255],   # urban_land\n",
    "        [255, 255, 0],   # agriculture_land\n",
    "        [255, 0, 255],   # rangeland\n",
    "        [0, 255, 0],     # forest_land\n",
    "        [0, 0, 255],     # water\n",
    "        [255, 255, 255], # barren_land\n",
    "        [0, 0, 0]        # unknown\n",
    "    ]\n",
    "    \n",
    "    one_hot_map = []\n",
    "    for colour in palette:\n",
    "        class_map = tf.reduce_all(tf.equal(image, colour), axis=-1)\n",
    "        one_hot_map.append(class_map)\n",
    "    one_hot_map = tf.stack(one_hot_map, axis=-1)\n",
    "    one_hot_map = tf.cast(one_hot_map, tf.uint8)\n",
    "    indexed = tf.math.argmax(one_hot_map, axis=2)\n",
    "    indexed = tf.cast(indexed, dtype=tf.uint8)\n",
    "    indexed = tf.expand_dims(indexed, -1)\n",
    "\n",
    "    return indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16d726b-155c-4be0-9e8e-5a9881853264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(datapoint, image_size):\n",
    "    \n",
    "    images = tf.image.resize(datapoint['image'], (image_size, image_size))\n",
    "\n",
    "    annotations = tf.map_fn(rgb_to_index, datapoint['segmentation_mask'])\n",
    "    annotations = tf.image.resize(annotations, (image_size, image_size), method='nearest')\n",
    "    \n",
    "    images = normalize(images)\n",
    "\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2416358-dfeb-4a8b-a8c0-bed9ea09de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    print(len(display_list))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e06716-38cb-406d-b3de-762095618338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 20:13:25.652678: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_valid, ds_test), ds_info = tfds.load(\n",
    "    name='deep_globe_2018',\n",
    "    download=False,\n",
    "    with_info=True,\n",
    "    split=['all_images[700:710]', 'all_images[7:9]', 'all_images[9:10]']\n",
    ")\n",
    "train_batches = (\n",
    "    ds_train\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x: load_images(x, IMAGE_SIZE), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "validation_batches = (\n",
    "    ds_valid\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x: load_images(x, IMAGE_SIZE), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_batches = (\n",
    "    ds_test\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x: load_images(x, IMAGE_SIZE), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926ea0e-ee1b-44c8-9cbf-605b592aa880",
   "metadata": {},
   "source": [
    "## Explore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23cfbad0-2136-476a-b9c8-a0017937adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb2621f-69f7-45fa-a880-e73868660e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers that need to be \"fully convolutionalized\" (layer sizes as per https://doi.org/10.48550/arXiv.1409.1556, last accessed: 22 Jan 2024)\n",
    "# Conversion as per: https://cs231n.github.io/convolutional-networks/#convert, last accessed: 22 Jan 2024\n",
    "\n",
    "# FC-4096\n",
    "block_6_conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=4096,\n",
    "    kernel_size=(7,7),\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation='relu'\n",
    ")\n",
    "\n",
    "# FC-4096\n",
    "block_6_conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=4096,\n",
    "    kernel_size=(7,7),\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation='relu'\n",
    ")\n",
    "\n",
    "# FC-1000 --> This final classifier layer is discarded\n",
    "# DO NOTHING\n",
    "\n",
    "# We append a 1 Ã— 1 convolution with channel dimension 21 to predict scores for each of the PASCAL classes at each of the coarse output locations\n",
    "# Looking at the original implementation there is no explicit activation function: https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn32s/net.py, last accessed 22.01.2024\n",
    "# Hence \"linear\" is chosen\n",
    "block_6_conv3 = tf.keras.layers.Conv2D(\n",
    "    filters=7,\n",
    "    kernel_size=(1,1),\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation='linear'\n",
    ")\n",
    "\n",
    "# followed by a deconvolution layer to bi-linearly upsample the coarse outputs to pixel-dense outputs\n",
    "block_6_deconv1 = tf.keras.layers.Conv2DTranspose(\n",
    "    filters=7,\n",
    "    kernel_size=(64, 64),\n",
    "    strides=(32, 32),\n",
    "    use_bias=False, # As per original implementation\n",
    "    padding='same',\n",
    "    activation='softmax'\n",
    ")\n",
    "block_6_deconv1.trainable = False # As per original implementation: param=[dict(lr_mult=0)]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67abb33a-e28b-45b6-8ada-c82483c9fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 20:18:40.004733: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (mklcpu) ran out of memory trying to allocate 3.06GiB (rounded to 3288334336)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-01-22 20:18:40.004804: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for mklcpu\n",
      "2024-01-22 20:18:40.004820: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004830: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004839: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004848: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004857: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004866: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004876: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004885: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004894: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004904: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004913: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004925: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 2, Chunks in use: 2. 1.14MiB allocated for chunks. 1.14MiB in use in bin. 1.14MiB client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004936: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.44MiB allocated for chunks. 1.44MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004945: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004955: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.00MiB allocated for chunks. 4.00MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004967: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 7, Chunks in use: 6. 73.43MiB allocated for chunks. 58.00MiB in use in bin. 49.50MiB client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004977: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004986: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 46.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.004995: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.005006: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 2, Chunks in use: 0. 368.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-22 20:18:40.005025: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 1. 1.52GiB allocated for chunks. 392.00MiB in use in bin. 392.00MiB client-requested in use in bin.\n",
      "2024-01-22 20:18:40.005036: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 3.06GiB was 256.00MiB, Chunk State: \n",
      "2024-01-22 20:18:40.005052: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 256.00MiB | Requested Size: 17.14MiB | in_use: 0 | bin_num: 20\n",
      "2024-01-22 20:18:40.005065: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 392.00MiB | Requested Size: 392.00MiB | in_use: 0 | bin_num: 20, next:   Size: 392.00MiB | Requested Size: 392.00MiB | in_use: 1 | bin_num: -1\n",
      "2024-01-22 20:18:40.005076: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 512.00MiB | Requested Size: 392.00MiB | in_use: 0 | bin_num: 20\n",
      "2024-01-22 20:18:40.005084: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2097152\n",
      "2024-01-22 20:18:40.005096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 55954082ee00 of size 589824 next 2\n",
      "2024-01-22 20:18:40.005105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5595408bee00 of size 1507328 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005112: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 1073741824\n",
      "2024-01-22 20:18:40.005121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7a5f6d7040 of size 411041792 next 7\n",
      "2024-01-22 20:18:40.005129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7a77ed7040 of size 411041792 next 32\n",
      "2024-01-22 20:18:40.005138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7a906d7040 of size 251658240 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005146: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 536870912\n",
      "2024-01-22 20:18:40.005154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7a9f6d8040 of size 536870912 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005162: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 268435456\n",
      "2024-01-22 20:18:40.005170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7abffd9040 of size 268435456 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005179: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 134217728\n",
      "2024-01-22 20:18:40.005188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7acffda040 of size 134217728 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005196: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 67108864\n",
      "2024-01-22 20:18:40.005205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7ae8ffd040 of size 9437184 next 15\n",
      "2024-01-22 20:18:40.005214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7ae98fd040 of size 9437184 next 16\n",
      "2024-01-22 20:18:40.005222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7aea1fd040 of size 48234496 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005230: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 33554432\n",
      "2024-01-22 20:18:40.005239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7aecffe040 of size 9437184 next 12\n",
      "2024-01-22 20:18:40.005247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7aed8fe040 of size 9437184 next 13\n",
      "2024-01-22 20:18:40.005256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7aee1fe040 of size 14680064 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005264: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 16777216\n",
      "2024-01-22 20:18:40.005273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7aeefff040 of size 602112 next 35\n",
      "2024-01-22 20:18:40.005281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f7aef092040 of size 16175104 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005289: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8388608\n",
      "2024-01-22 20:18:40.005300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7b04b59040 of size 8388608 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005308: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4194304\n",
      "2024-01-22 20:18:40.005318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7b0535a040 of size 4194304 next 18446744073709551615\n",
      "2024-01-22 20:18:40.005326: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-01-22 20:18:40.005337: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2024-01-22 20:18:40.005348: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 602112 totalling 588.0KiB\n",
      "2024-01-22 20:18:40.005359: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1507328 totalling 1.44MiB\n",
      "2024-01-22 20:18:40.005368: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4194304 totalling 4.00MiB\n",
      "2024-01-22 20:18:40.005377: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8388608 totalling 8.00MiB\n",
      "2024-01-22 20:18:40.005387: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 9437184 totalling 36.00MiB\n",
      "2024-01-22 20:18:40.005397: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14680064 totalling 14.00MiB\n",
      "2024-01-22 20:18:40.005408: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 411041792 totalling 392.00MiB\n",
      "2024-01-22 20:18:40.005419: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 456.57MiB\n",
      "2024-01-22 20:18:40.005429: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 2145386496 memory_limit_: 4034572288 available bytes: 1889185792 curr_region_allocation_bytes_: 2147483648\n",
      "2024-01-22 20:18:40.005444: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      4034572288\n",
      "InUse:                       478752768\n",
      "MaxInUse:                   1426665472\n",
      "NumAllocs:                         169\n",
      "MaxAllocSize:                536870912\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-01-22 20:18:40.005458: W tensorflow/tsl/framework/bfc_allocator.cc:497] *__________________********************______________________________________________________**__***\n",
      "2024-01-22 20:18:40.005493: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at stateless_random_ops_v2.cc:64 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[7,7,4096,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[7,7,4096,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:StatelessRandomUniformV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m base_model(inputs)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m block_6_conv1(x)\n\u001b[0;32m----> 4\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mblock_6_conv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m block_6_conv3(x) \u001b[38;5;66;03m#scoring layer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m block_6_deconv1(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/backend.py:2102\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2101\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2110\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2111\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2114\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2115\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[7,7,4096,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:StatelessRandomUniformV2] name: "
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs)\n",
    "x = block_6_conv1(x)\n",
    "x = block_6_conv2(x)\n",
    "x = block_6_conv3(x) #scoring layer\n",
    "x = block_6_deconv1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b7b9cb-99bd-4436-9a6b-4fa229c50de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in train_batches.take(1):\n",
    "    y = base_model(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238b60b5-0806-4bcf-95e6-638e1ada88ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b8715-9734-4cec-a069-565e2c30aebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
