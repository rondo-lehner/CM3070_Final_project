{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94fe28fa-bf08-4199-b93b-4c6b75c3f264",
   "metadata": {},
   "source": [
    "# Dataset pipeline for Early Convnet Approach (Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc694f-eb96-409c-968e-b215e491d572",
   "metadata": {},
   "source": [
    "Possible leads:\n",
    "* https://stackoverflow.com/questions/54745903/how-to-implement-an-image2d-array-sequence-sliding-window-in-tensorflow\n",
    "* https://stackoverflow.com/questions/55429307/how-to-use-windows-created-by-the-dataset-window-method-in-tensorflow-2-0s\n",
    "* https://stackoverflow.com/questions/38235643/getting-started-with-tensorflow-split-image-into-sub-imagess\n",
    "\n",
    "Goal:s\n",
    "> every 40 Ã— 40 window in the input stepped every 4 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831a1481-e273-4982-87c5-ba58de126957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 20:54:34.944877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-26 20:54:42.246840: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='deep_globe_2018',\n",
       "    full_name='deep_globe_2018/1.0.0',\n",
       "    description=\"\"\"\n",
       "    TODO(deep_globe_2018): Markdown description of that will appear on the catalog page.\n",
       "    Description is **formatted** as markdown.\n",
       "    \n",
       "    It should also contain any processing which has been applied (if any),\n",
       "    (e.g. corrupted example skipped, images cropped,...):\n",
       "    \"\"\",\n",
       "    homepage='https://dataset-homepage/',\n",
       "    data_path='/root/tensorflow_datasets/deep_globe_2018/1.0.0',\n",
       "    file_format=tfrecord,\n",
       "    download_size=Unknown size,\n",
       "    dataset_size=1.95 GiB,\n",
       "    features=FeaturesDict({\n",
       "        'file_name': Text(shape=(), dtype=string),\n",
       "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
       "        'segmentation_mask': Image(shape=(None, None, 1), dtype=uint8),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'all_images': <SplitInfo num_examples=803, num_shards=16>,\n",
       "    },\n",
       "    citation=\"\"\"// TODO(deep_globe_2018): BibTeX citation\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import src.data.datasets.deep_globe_2018\n",
    "import PIL\n",
    "\n",
    "ds, ds_info = tfds.load(\n",
    "        # Useful link: https://github.com/tensorflow/datasets/issues/2680#issuecomment-778801923\n",
    "        name='deep_globe_2018',\n",
    "        download=False,\n",
    "        with_info=True,\n",
    "    )\n",
    "\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1cdbb7f-5c80-4f4d-b0e3-da4d22bb2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(datapoint):    \n",
    "    input_image = tf.image.resize(datapoint['image'], (512, 512))\n",
    "    \n",
    "    input_mask = tf.image.resize(\n",
    "        datapoint['segmentation_mask'],\n",
    "        (512, 512),\n",
    "        method = tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "    )\n",
    "    \n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d39544-fc67-484a-8cd7-5d37d4196a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  input_mask -= 1\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56bff6fd-fd35-425b-a887-120104bc019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca1818c1-2db3-4866-bfef-1840e394fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ds['all_images'].take(10).map(load_image, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0395749-fb14-4ca6-a9dc-5d31c20419ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._ParallelMapDataset"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11cdfd1c-80a9-4460-9caf-451551071bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batches = (\n",
    "    images\n",
    "    .cache() # The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data.\n",
    "    .window( size=40, shift=4, drop_remainder=True ).flat_map( lambda x, y: tf.data.Dataset.zip( (x.batch(40), y.batch(40)) ) )\n",
    "    # .batch(1) # Combines consecutive elements of this dataset into batches.\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "for i, m in image_batches.take(2):\n",
    "    sample_image, sample_mask = i[0], m[0]\n",
    "    display([sample_image, sample_mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
