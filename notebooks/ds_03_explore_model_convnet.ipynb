{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf0c256-3310-4718-880d-b7a3e22538fb",
   "metadata": {},
   "source": [
    "# Explore the EarlyConvNet model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c52de95-0516-45d7-9e5c-b3fa1a81a0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-01 21:03:50.118138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src.models import early_convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2d02d-34cd-4194-a82e-e1e3cd6df46c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e432247-4ce7-4761-9c0a-a0df605b53fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import src.data.datasets.deep_globe_2018\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11468dd-45af-4a8f-b066-5e79086c5cc0",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5015853-08a3-4e8b-8ee0-307097e66aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "batch_size_images = 1\n",
    "batch_size_patches = 1\n",
    "img_size = 612\n",
    "patch_size = 80\n",
    "patch_size_annotation = 2\n",
    "patch_stride = 32\n",
    "\n",
    "## Training\n",
    "epochs = 2\n",
    "class_weights = {\n",
    "        0: 6.070,    # urban_land\n",
    "        1: 1.,       # agriculture_land\n",
    "        2: 5.559,    # rangeland\n",
    "        3: 4.128,    # forest_land\n",
    "        4: 15.176,   # water\n",
    "        5: 9.244,    # barren_land\n",
    "        6: 100.       # unknown - Note: not to scale with respect to the others but not that important for the overall classification\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07693c9-cb1a-4cda-a2a2-2bb849754373",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71f0b8c-cc25-4e7a-a19a-6d1fcc06771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb39cf8-1943-4ecb-9805-ca83bba81bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_index(image):\n",
    "    palette = [\n",
    "        [0, 255, 255],   # urban_land\n",
    "        [255, 255, 0],   # agriculture_land\n",
    "        [255, 0, 255],   # rangeland\n",
    "        [0, 255, 0],     # forest_land\n",
    "        [0, 0, 255],     # water\n",
    "        [255, 255, 255], # barren_land\n",
    "        [0, 0, 0]        # unknown\n",
    "    ]\n",
    "    \n",
    "    one_hot_map = []\n",
    "    for colour in palette:\n",
    "        class_map = tf.reduce_all(tf.equal(image, colour), axis=-1)\n",
    "        one_hot_map.append(class_map)\n",
    "    one_hot_map = tf.stack(one_hot_map, axis=-1)\n",
    "    one_hot_map = tf.cast(one_hot_map, tf.uint8)\n",
    "    indexed = tf.math.argmax(one_hot_map, axis=2)\n",
    "    indexed = tf.cast(indexed, dtype=tf.uint8)\n",
    "    indexed = tf.expand_dims(indexed, -1)\n",
    "\n",
    "    return indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc9cacd-fab0-4ee9-b65d-2bc9218b3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mode(tensor):\n",
    "    y, idx, count = tf.unique_with_counts(tensor)\n",
    "    mode = y[tf.argmax(count)]\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089a3e87-0c9d-4bce-84c6-1a590ed3b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patches_labels(datapoint, image_size, patch_size, patch_size_annotation, stride):\n",
    "    crop_fraction = patch_size_annotation / patch_size\n",
    "    \n",
    "    images = tf.image.resize(datapoint['image'], (image_size, image_size))\n",
    "    img_patches = tf.image.extract_patches(\n",
    "        images = images,\n",
    "        sizes = [1, patch_size, patch_size, 1],\n",
    "        strides = [1, stride, stride, 1],\n",
    "        rates = [1, 1, 1, 1],\n",
    "        padding = 'VALID'\n",
    "    )\n",
    "    img_patches_flat = tf.reshape(img_patches, shape=(-1, patch_size, patch_size, 3))\n",
    "\n",
    "    annotations = tf.map_fn(rgb_to_index, datapoint['segmentation_mask'])\n",
    "    annotations = tf.image.resize(annotations, (image_size, image_size), method='nearest')\n",
    "\n",
    "    ann_patches = tf.image.extract_patches(\n",
    "        images = annotations,\n",
    "        sizes = [1, patch_size, patch_size, 1],\n",
    "        strides = [1, stride, stride, 1],\n",
    "        rates = [1, 1, 1, 1],\n",
    "        padding = 'VALID'\n",
    "    )\n",
    "    ann_patches_flat = tf.reshape(ann_patches, shape=(-1, patch_size, patch_size, 1))\n",
    "    central_pixels = tf.image.central_crop(ann_patches_flat, crop_fraction)\n",
    "    dim = tf.reduce_prod(tf.shape(central_pixels)[1:])\n",
    "    central_pixels = tf.reshape(central_pixels, [-1, dim])\n",
    "\n",
    "    # pixel_category_idx = tf.map_fn(reduce_mode, central_pixels)\n",
    "    # print(central_pixels)\n",
    "    pixel_category_idx = tf.reduce_max(central_pixels, axis=1) # reduce_mode is probably preferred but I chose a simpler implementation\n",
    "\n",
    "    img_patches_flat = normalize(img_patches_flat)\n",
    "    pixel_category_one_hot = tf.one_hot(\n",
    "        pixel_category_idx,\n",
    "        depth = 7, # TODO: make depth configurable\n",
    "        on_value = 1,\n",
    "        off_value = -1\n",
    "    )\n",
    "\n",
    "    return img_patches_flat, pixel_category_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02daaf1c-c010-4fc5-a3f1-3bf059271748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    print(len(display_list))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eedafc-7e04-4473-befa-099c24c63e11",
   "metadata": {},
   "source": [
    "## Optimizer, loss function, dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db1600-8da7-41f1-96b0-ec53d115a1ec",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd10c20-20bd-4ce6-b7d6-05029047753c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_valid, ds_test), ds_info = tfds.load(\n",
    "    name='deep_globe_2018',\n",
    "    download=False,\n",
    "    with_info=True,\n",
    "    split=['all_images[:70%]', 'all_images[70%:90%]', 'all_images[90%:]']\n",
    ")\n",
    "train_batches = (\n",
    "    ds_train\n",
    "    .batch(batch_size_images)\n",
    "    .map(lambda x: load_patches_labels(x, img_size, patch_size, patch_size_annotation, patch_stride), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .unbatch() # Flatten the batches for training\n",
    "    .batch(batch_size_patches) # Rebatch patches as desired\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "validation_batches = (\n",
    "    ds_valid\n",
    "    .batch(batch_size_images)\n",
    "    .map(lambda x: load_patches_labels(x, img_size, patch_size, patch_size_annotation, patch_stride), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .unbatch() # Flatten the batches for training\n",
    "    .batch(batch_size_patches) # Rebatch patches as desired\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "test_batches = (\n",
    "    ds_test\n",
    "    .batch(batch_size_images)\n",
    "    .map(lambda x: load_patches_labels(x, img_size, patch_size, patch_size_annotation, patch_stride), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ## unbatching not required for testing\n",
    "    # .unbatch() # Flatten the batches for training\n",
    "    # .batch(batch_size_patches) # Rebatch patches as desired\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")    \n",
    "# ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7957665b-7a5c-4f99-a496-066e6f724aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show label distribution\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# vals = np.fromiter(train_batches.map(lambda x, y: tf.argmax(y, axis=1)), float)\n",
    "# plt.hist(vals)\n",
    "# plt.xticks(range(7))\n",
    "# plt.title('Label Frequency')\n",
    "# plt.show()\n",
    "# # np.unique(vals, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c599a68-032f-4d6c-b922-b7eb93852f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batches = (\n",
    "#     ds_train\n",
    "#     .take(1)\n",
    "#     .batch(1)\n",
    "#     .map(lambda x: load_patches_labels(x, img_size, patch_size, patch_size_annotation, patch_stride), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "# )\n",
    "# for i, m in train_batches.take(1):\n",
    "#     sample_images = i[1190:1210]\n",
    "#     sample_masks = m[1190:1210]\n",
    "#     print(i.shape, m.shape)\n",
    "#     # samples = list(zip(sample_images, sample_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056e06e-23e5-4869-8355-69aa04e17fdf",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a387c081-533b-4e31-b4c7-878bbbc0d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af38675-6e15-49af-99c6-c53eb2966862",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be50f53f-c5c9-43a3-a4a9-29734a88aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee141b-7c81-4472-b13c-911b94e21ac4",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df2aea0d-b768-4aa7-a158-4a9c41c16769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = early_convnet.EarlyConvnet()\n",
    "model.build((None, patch_size, patch_size, 3))\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss_fn,\n",
    "    metrics = ['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bd610-0f65-412d-b996-74230db9a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "162418/162418 [==============================] - 2372s 15ms/step - loss: 4.2486 - mse: 1.2161 - val_loss: 1.2166 - val_mse: 1.2167\n",
      "Epoch 2/2\n",
      "162415/162418 [============================>.] - ETA: 0s - loss: 4.2478 - mse: 1.2158"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_batches,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_batches,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30326003-c839-4c0a-97b8-eb32e0bceb08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i,m in test_batches.take(1):\n",
    "#     y = model.predict(i)\n",
    "#     mask = tf.reshape(tf.argmax(input=y, axis=3), shape=(1, 17, 17, 1))\n",
    "#     display(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b19c0e5-5da8-4476-868a-5d06d429b92a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 40, 40, 3)]       0         \n",
      "                                                                 \n",
      " C1 (Conv2D)                 (None, 34, 34, 6)         888       \n",
      "                                                                 \n",
      " S2 (Subsampling)            (None, 17, 17, 6)         12        \n",
      "                                                                 \n",
      " C3 (Conv2D)                 (None, 12, 12, 16)        3472      \n",
      "                                                                 \n",
      " S4 (Subsampling)            (None, 6, 6, 16)          32        \n",
      "                                                                 \n",
      " C5 (Conv2D)                 (None, 1, 1, 40)          23080     \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 1, 1, 7)           287       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27771 (108.48 KB)\n",
      "Trainable params: 27771 (108.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.build((None, patch_size, patch_size, 3))\n",
    "# raw_input = (patch_size, patch_size, 3)\n",
    "# y = model(tf.ones(shape=(8,*raw_input))) \n",
    "model.build_graph(raw_input).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e3afe-23aa-4e15-a529-175c2abe0fd8",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a05d84c-ec04-44fd-8919-67a6c896dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "(8, 1, 1, 7)\n",
      "(8, 7)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'The optimizer cannot recognize variable early_convnet_3/C1/kernel:0. This usually means you are trying to call the optimizer to update different parts of the model separately. Please call `optimizer.build(variables)` with the full list of trainable variables before the training loop or use legacy optimizer `tf.keras.optimizers.legacy.SGD.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_fn(cat_batch_train, logits)\n\u001b[1;32m     12\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[0;32m---> 13\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss (for one batch) at step \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;241m%\u001b[39m (step, \u001b[38;5;28mfloat\u001b[39m(loss_value))\n\u001b[1;32m     19\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1230\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1229\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:652\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    651\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 652\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1260\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m-> 1260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply_gradients_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1352\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1352\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1357\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2992\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2989\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2990\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2991\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2994\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2995\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4062\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4060\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4061\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4062\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4068\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4064\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4065\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4066\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4067\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4068\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4070\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1349\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step_xla(grad, var, \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(var)))\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:233\u001b[0m, in \u001b[0;36m_BaseOptimizer._update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(variable) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe optimizer cannot recognize variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis usually means you are trying to call the optimizer to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate different parts of the model separately. Please call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`optimizer.build(variables)` with the full list of trainable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables before the training loop or use legacy optimizer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(gradient, variable)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'The optimizer cannot recognize variable early_convnet_3/C1/kernel:0. This usually means you are trying to call the optimizer to update different parts of the model separately. Please call `optimizer.build(variables)` with the full list of trainable variables before the training loop or use legacy optimizer `tf.keras.optimizers.legacy.SGD.'"
     ]
    }
   ],
   "source": [
    "# Source: https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch (last accessed 31.12.2023)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    \n",
    "    for step, (img_batch_train, cat_batch_train) in enumerate(train_batches):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(img_batch_train, training=True)\n",
    "            print(logits.shape)\n",
    "            print(cat_batch_train.shape)\n",
    "            loss_value = loss_fn(cat_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
